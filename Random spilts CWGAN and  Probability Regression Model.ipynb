{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfUZh4ijnQ0I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0cOzxdnEyfK",
    "outputId": "9452a5be-c98d-45d0-d6c1-e9a3036696c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196776 entries, 0 to 196775\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Time                    196776 non-null  object \n",
      " 1   Energy delta[Wh]        196776 non-null  int64  \n",
      " 2   GHI                     196776 non-null  float64\n",
      " 3   temp                    196776 non-null  float64\n",
      " 4   pressure                196776 non-null  int64  \n",
      " 5   humidity                196776 non-null  int64  \n",
      " 6   wind_speed              196776 non-null  float64\n",
      " 7   rain_1h                 196776 non-null  float64\n",
      " 8   snow_1h                 196776 non-null  float64\n",
      " 9   clouds_all              196776 non-null  int64  \n",
      " 10  isSun                   196776 non-null  int64  \n",
      " 11  sunlightTime            196776 non-null  int64  \n",
      " 12  dayLength               196776 non-null  int64  \n",
      " 13  SunlightTime/daylength  196776 non-null  float64\n",
      " 14  weather_type            196776 non-null  int64  \n",
      " 15  hour                    196776 non-null  int64  \n",
      " 16  month                   196776 non-null  int64  \n",
      "dtypes: float64(6), int64(10), object(1)\n",
      "memory usage: 25.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  Time  Energy delta[Wh]  GHI  temp  pressure  humidity  \\\n",
       " 0  2017-01-01 00:00:00                 0  0.0   1.6      1021       100   \n",
       " 1  2017-01-01 00:15:00                 0  0.0   1.6      1021       100   \n",
       " 2  2017-01-01 00:30:00                 0  0.0   1.6      1021       100   \n",
       " 3  2017-01-01 00:45:00                 0  0.0   1.6      1021       100   \n",
       " 4  2017-01-01 01:00:00                 0  0.0   1.7      1020       100   \n",
       " \n",
       "    wind_speed  rain_1h  snow_1h  clouds_all  isSun  sunlightTime  dayLength  \\\n",
       " 0         4.9      0.0      0.0         100      0             0        450   \n",
       " 1         4.9      0.0      0.0         100      0             0        450   \n",
       " 2         4.9      0.0      0.0         100      0             0        450   \n",
       " 3         4.9      0.0      0.0         100      0             0        450   \n",
       " 4         5.2      0.0      0.0         100      0             0        450   \n",
       " \n",
       "    SunlightTime/daylength  weather_type  hour  month  \n",
       " 0                     0.0             4     0      1  \n",
       " 1                     0.0             4     0      1  \n",
       " 2                     0.0             4     0      1  \n",
       " 3                     0.0             4     0      1  \n",
       " 4                     0.0             4     1      1  ,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "renewable_data = pd.read_csv('/home/joseph/Downloads/Renewable.csv')\n",
    "renewable_data_head = renewable_data.head()\n",
    "renewable_data_info = renewable_data.info()\n",
    "# Check basic info to see column types and any missing values\n",
    "renewable_data_info\n",
    "renewable_data_head,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "75bactp9HeWX",
    "outputId": "2416ef7d-c22a-43f2-e03c-37f5bcfb6254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 196753 entries, 23 to 196775\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   Time                    196753 non-null  datetime64[ns]\n",
      " 1   Energy delta[Wh]        196753 non-null  float64       \n",
      " 2   GHI                     196753 non-null  float64       \n",
      " 3   temp                    196753 non-null  float64       \n",
      " 4   pressure                196753 non-null  int64         \n",
      " 5   humidity                196753 non-null  float64       \n",
      " 6   wind_speed              196753 non-null  float64       \n",
      " 7   rain_1h                 196753 non-null  float64       \n",
      " 8   snow_1h                 196753 non-null  float64       \n",
      " 9   clouds_all              196753 non-null  int64         \n",
      " 10  isSun                   196753 non-null  int64         \n",
      " 11  sunlightTime            196753 non-null  int64         \n",
      " 12  dayLength               196753 non-null  int64         \n",
      " 13  SunlightTime/daylength  196753 non-null  float64       \n",
      " 14  weather_type            196753 non-null  float64       \n",
      " 15  hour                    196753 non-null  int64         \n",
      " 16  month                   196753 non-null  int64         \n",
      " 17  day_of_week             196753 non-null  int64         \n",
      " 18  hour_of_day             196753 non-null  int64         \n",
      " 19  season                  196753 non-null  int64         \n",
      " 20  lag_1                   196753 non-null  float64       \n",
      " 21  lag_2                   196753 non-null  float64       \n",
      " 22  rolling_mean_24         196753 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(12), int64(10)\n",
      "memory usage: 36.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  Time  Energy delta[Wh]  GHI      temp  pressure  humidity  \\\n",
       " 23 2017-01-01 05:45:00               0.0  0.0  0.366412      1017       1.0   \n",
       " 24 2017-01-01 06:00:00               0.0  0.0  0.370229      1017       1.0   \n",
       " 25 2017-01-01 06:15:00               0.0  0.0  0.370229      1017       1.0   \n",
       " 26 2017-01-01 06:30:00               0.0  0.0  0.370229      1017       1.0   \n",
       " 27 2017-01-01 06:45:00               0.0  0.0  0.370229      1017       1.0   \n",
       " \n",
       "     wind_speed  rain_1h  snow_1h  clouds_all  ...  SunlightTime/daylength  \\\n",
       " 23    0.398601      0.0      0.0         100  ...                     0.0   \n",
       " 24    0.419580      0.0      0.0         100  ...                     0.0   \n",
       " 25    0.419580      0.0      0.0         100  ...                     0.0   \n",
       " 26    0.419580      0.0      0.0         100  ...                     0.0   \n",
       " 27    0.419580      0.0      0.0         100  ...                     0.0   \n",
       " \n",
       "     weather_type  hour  month  day_of_week  hour_of_day  season  lag_1  lag_2  \\\n",
       " 23           3.0     5      1            6            5       1    0.0    0.0   \n",
       " 24           3.0     6      1            6            6       1    0.0    0.0   \n",
       " 25           3.0     6      1            6            6       1    0.0    0.0   \n",
       " 26           3.0     6      1            6            6       1    0.0    0.0   \n",
       " 27           3.0     6      1            6            6       1    0.0    0.0   \n",
       " \n",
       "     rolling_mean_24  \n",
       " 23              0.0  \n",
       " 24              0.0  \n",
       " 25              0.0  \n",
       " 26              0.0  \n",
       " 27              0.0  \n",
       " \n",
       " [5 rows x 23 columns],\n",
       " None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "renewable_data['Time'] = pd.to_datetime(renewable_data['Time'])#\n",
    "renewable_data_cleaned = renewable_data.drop_duplicates()\n",
    "renewable_data_cleaned['Energy delta[Wh]'] = renewable_data_cleaned['Energy delta[Wh]'].clip(upper=5020)\n",
    "renewable_data_cleaned['GHI'] = renewable_data_cleaned['GHI'].clip(upper=229.2)\n",
    "renewable_data_cleaned['temp'] = renewable_data_cleaned['temp'].clip(lower=-16.6, upper=35.8)\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = ['Energy delta[Wh]', 'GHI', 'temp', 'wind_speed', 'humidity']\n",
    "renewable_data_cleaned[columns_to_scale] = scaler.fit_transform(renewable_data_cleaned[columns_to_scale])\n",
    "renewable_data_cleaned['day_of_week'] = renewable_data_cleaned['Time'].dt.dayofweek\n",
    "renewable_data_cleaned['hour_of_day'] = renewable_data_cleaned['Time'].dt.hour\n",
    "renewable_data_cleaned['season'] = renewable_data_cleaned['month'].apply(lambda x: (x%12 + 3)//3)\n",
    "renewable_data['Time'] = pd.to_datetime(renewable_data['Time'])\n",
    "renewable_data_cleaned = renewable_data.drop_duplicates()\n",
    "# Handling outliers by capping extreme values (for Energy delta[Wh], GHI, and temp)\n",
    "renewable_data_cleaned['Energy delta[Wh]'] = renewable_data_cleaned['Energy delta[Wh]'].clip(upper=5020)\n",
    "renewable_data_cleaned['GHI'] = renewable_data_cleaned['GHI'].clip(upper=229.2)\n",
    "renewable_data_cleaned['temp'] = renewable_data_cleaned['temp'].clip(lower=-16.6, upper=35.8)\n",
    "scaler = MinMaxScaler()\n",
    "columns_to_scale = ['Energy delta[Wh]', 'GHI', 'temp', 'wind_speed', 'humidity']\n",
    "renewable_data_cleaned[columns_to_scale] = scaler.fit_transform(renewable_data_cleaned[columns_to_scale])\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "renewable_data_cleaned['weather_type'] = ordinal_encoder.fit_transform(renewable_data_cleaned[['weather_type']])\n",
    "renewable_data_cleaned['day_of_week'] = renewable_data_cleaned['Time'].dt.dayofweek\n",
    "renewable_data_cleaned['hour_of_day'] = renewable_data_cleaned['Time'].dt.hour\n",
    "renewable_data_cleaned['season'] = renewable_data_cleaned['month'].apply(lambda x: (x%12 + 3)//3)\n",
    "renewable_data_cleaned['lag_1'] = renewable_data_cleaned['Energy delta[Wh]'].shift(1)\n",
    "renewable_data_cleaned['lag_2'] = renewable_data_cleaned['Energy delta[Wh]'].shift(2)\n",
    "renewable_data_cleaned['rolling_mean_24'] = renewable_data_cleaned['Energy delta[Wh]'].rolling(window=24).mean()\n",
    "renewable_data_cleaned = renewable_data_cleaned.dropna()\n",
    "renewable_data_cleaned.head(), renewable_data_cleaned.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLvGxSvGH-cv",
    "outputId": "9d591e56-57c8-49ec-956e-36b5ffd05d19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((157402, 21), (39351, 21), (157402,), (39351,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = renewable_data_cleaned.drop(columns=['Energy delta[Wh]', 'Time'])\n",
    "y = renewable_data_cleaned['Energy delta[Wh]']\n",
    "\n",
    "# Split the data into training and testing sets (80% for training and 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the sizes of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHI</th>\n",
       "      <th>temp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>isSun</th>\n",
       "      <th>sunlightTime</th>\n",
       "      <th>...</th>\n",
       "      <th>SunlightTime/daylength</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>season</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>rolling_mean_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63165</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.471374</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.426573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53446</th>\n",
       "      <td>0.119983</td>\n",
       "      <td>0.784351</td>\n",
       "      <td>1012</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.244755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.080279</td>\n",
       "      <td>0.092629</td>\n",
       "      <td>0.394065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171901</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314885</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53818</th>\n",
       "      <td>0.657068</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.251748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551594</td>\n",
       "      <td>0.599278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284351</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GHI      temp  pressure  humidity  wind_speed  rain_1h  snow_1h  \\\n",
       "63165   0.000000  0.471374      1008  0.730769    0.426573      0.0      0.0   \n",
       "53446   0.119983  0.784351      1012  0.564103    0.244755      0.0      0.0   \n",
       "171901  0.000000  0.314885      1007  0.871795    0.286713      0.0      0.0   \n",
       "53818   0.657068  0.763359      1013  0.410256    0.251748      0.0      0.0   \n",
       "2177    0.000000  0.284351      1021  0.717949    0.272727      0.0      0.0   \n",
       "\n",
       "        clouds_all  isSun  sunlightTime  ...  SunlightTime/daylength  \\\n",
       "63165           51      0             0  ...                    0.00   \n",
       "53446           98      1           900  ...                    0.91   \n",
       "171901         100      0             0  ...                    0.00   \n",
       "53818           21      1           705  ...                    0.72   \n",
       "2177             2      0             0  ...                    0.00   \n",
       "\n",
       "        weather_type  hour  month  day_of_week  hour_of_day  season     lag_1  \\\n",
       "63165            2.0    23     10            3           23       4  0.000000   \n",
       "53446            3.0    17      7            0           17       3  0.080279   \n",
       "171901           3.0    15     12            6           15       1  0.000000   \n",
       "53818            1.0    14      7            4           14       3  0.500000   \n",
       "2177             0.0    16      1            5           16       1  0.000000   \n",
       "\n",
       "           lag_2  rolling_mean_24  \n",
       "63165   0.000000         0.000000  \n",
       "53446   0.092629         0.394065  \n",
       "171901  0.000000         0.007263  \n",
       "53818   0.551594         0.599278  \n",
       "2177    0.000000         0.313803  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "from sklearn.linear_model import BayesianRidge, QuantileRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes - X_train: (157402, 21), X_test: (39351, 21), y_train: (157402,), y_test: (39351,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure consistent datatypes by setting TensorFlow's default float type\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Using the X_train, X_test, y_train, y_test from the main code\n",
    "# Scale the data for neural network models\n",
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test_scaled = X_scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten().astype(np.float32)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_scaled))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test_scaled))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "print(f\"Data shapes - X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "class WGAN_GP:\n",
    "    def __init__(self, input_dim, latent_dim=100, gp_weight=10.0):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gp_weight = gp_weight\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.generator_optimizer = keras.optimizers.Adam(0.00005, beta_1=0.5, beta_2=0.9)\n",
    "        self.discriminator_optimizer = keras.optimizers.Adam(0.00005, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise_input = keras.Input(shape=(self.latent_dim,))\n",
    "        cond_input = keras.Input(shape=(self.input_dim,))\n",
    "\n",
    "        # Process conditional input\n",
    "        c = layers.Dense(64)(cond_input)\n",
    "        c = layers.LeakyReLU(0.2)(c)\n",
    "        c = layers.BatchNormalization()(c)\n",
    "\n",
    "        # Process noise\n",
    "        z = layers.Dense(64)(noise_input)\n",
    "        z = layers.LeakyReLU(0.2)(z)\n",
    "        z = layers.BatchNormalization()(z)\n",
    "\n",
    "        # Merge inputs\n",
    "        merged = layers.Concatenate()([z, c])\n",
    "\n",
    "        # Generator network with residual connections\n",
    "        x = layers.Dense(128)(merged)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Residual block 1\n",
    "        res = x\n",
    "        x = layers.Dense(128)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dense(128)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Add()([x, res])\n",
    "\n",
    "        x = layers.Dense(64)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        # Output layer - prediction\n",
    "        output = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "        model = keras.Model([noise_input, cond_input], output, name=\"generator\")\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        energy_input = keras.Input(shape=(1,))\n",
    "        cond_input = keras.Input(shape=(self.input_dim,))\n",
    "\n",
    "        # Process conditional input\n",
    "        c = layers.Dense(64)(cond_input)\n",
    "        c = layers.LeakyReLU(0.2)(c)\n",
    "\n",
    "        # Process energy value\n",
    "        e = layers.Dense(32)(energy_input)\n",
    "        e = layers.LeakyReLU(0.2)(e)\n",
    "\n",
    "        # Merge inputs\n",
    "        merged = layers.Concatenate()([e, c])\n",
    "\n",
    "        x = layers.Dense(128)(merged)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        x = layers.Dense(128)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "        # No sigmoid for Wasserstein - output raw score\n",
    "        validity = layers.Dense(1)(x)\n",
    "\n",
    "        model = keras.Model([energy_input, cond_input], validity, name=\"discriminator\")\n",
    "        return model\n",
    "\n",
    "    # Gradient penalty function\n",
    "    def gradient_penalty(self, real_samples, fake_samples, cond_input):\n",
    "        batch_size = tf.shape(real_samples)[0]\n",
    "        alpha = tf.random.uniform(shape=[batch_size, 1], minval=0.0, maxval=1.0)\n",
    "\n",
    "        # Interpolation between real and fake\n",
    "        interpolates = alpha * real_samples + (1 - alpha) * fake_samples\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolates)\n",
    "            pred = self.discriminator([interpolates, cond_input])\n",
    "\n",
    "        grads = gp_tape.gradient(pred, interpolates)\n",
    "        grad_norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-8)\n",
    "        return tf.reduce_mean((grad_norm - 1.0) ** 2)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step_discriminator(self, real_energy, real_conditions):\n",
    "        batch_size = tf.shape(real_energy)[0]\n",
    "\n",
    "        # Generate random noise\n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "\n",
    "        # Generate fake energy predictions\n",
    "        fake_energy = self.generator([noise, real_conditions])\n",
    "\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            # Get critic scores\n",
    "            real_output = self.discriminator([real_energy, real_conditions])\n",
    "            fake_output = self.discriminator([fake_energy, real_conditions])\n",
    "            disc_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "            # Calculate gradient penalty\n",
    "            gp = self.gradient_penalty(real_energy, fake_energy, real_conditions)\n",
    "\n",
    "            # Add gradient penalty to loss\n",
    "            disc_loss += self.gp_weight * gp\n",
    "\n",
    "        # Get gradients\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        # Apply gradients\n",
    "        self.discriminator_optimizer.apply_gradients(\n",
    "            zip(disc_gradients, self.discriminator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return disc_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step_generator(self, real_conditions):\n",
    "        batch_size = tf.shape(real_conditions)[0]\n",
    "\n",
    "        # Generate random noise\n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # Generate fake energy predictions\n",
    "            fake_energy = self.generator([noise, real_conditions])\n",
    "\n",
    "            # Get critic score on fake data\n",
    "            fake_output = self.discriminator([fake_energy, real_conditions])\n",
    "\n",
    "            # Calculate generator loss\n",
    "            gen_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "        # Get gradients\n",
    "        gen_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "\n",
    "        # Apply gradients\n",
    "        self.generator_optimizer.apply_gradients(\n",
    "            zip(gen_gradients, self.generator.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return gen_loss\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=100, batch_size=64, n_critic=5):\n",
    "        \"\"\"Train the WGAN-GP model\"\"\"\n",
    "        # Convert inputs to tensors\n",
    "        X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "        y_train = tf.convert_to_tensor(y_train.reshape(-1, 1), dtype=tf.float32)\n",
    "\n",
    "        # Create dataset\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((y_train, X_train))\n",
    "        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            d_loss_epoch = []\n",
    "            g_loss_epoch = []\n",
    "\n",
    "            for batch_idx, (real_energy, real_conditions) in enumerate(dataset):\n",
    "                # Train discriminator multiple times\n",
    "                for _ in range(n_critic):\n",
    "                    d_loss = self.train_step_discriminator(real_energy, real_conditions)\n",
    "                    d_loss_epoch.append(d_loss)\n",
    "\n",
    "                # Train generator once\n",
    "                g_loss = self.train_step_generator(real_conditions)\n",
    "                g_loss_epoch.append(g_loss)\n",
    "\n",
    "            # Average losses\n",
    "            avg_d_loss = tf.reduce_mean(d_loss_epoch)\n",
    "            avg_g_loss = tf.reduce_mean(g_loss_epoch)\n",
    "\n",
    "            d_losses.append(avg_d_loss)\n",
    "            g_losses.append(avg_g_loss)\n",
    "\n",
    "            # Print progress\n",
    "            if epoch % 5 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs} [D loss: {avg_d_loss:.4f}] [G loss: {avg_g_loss:.4f}]\")\n",
    "\n",
    "        # Plot training curves\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(d_losses, label='Critic Loss')\n",
    "        plt.plot(g_losses, label='Generator Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend() \n",
    "        plt.title('CWGAN-GP Training History')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return d_losses, g_losses\n",
    "\n",
    "    def predict(self, X_test, num_samples=1000):\n",
    "        \"\"\"Generate predictions by averaging multiple samples\"\"\"\n",
    "        X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "        predictions = []\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            noise = tf.random.normal([X_test.shape[0], self.latent_dim])\n",
    "            pred = self.generator.predict([noise, X_test], verbose=0)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        # Stack predictions and compute mean and std\n",
    "        stacked_preds = np.hstack(predictions)\n",
    "        avg_predictions = np.mean(stacked_preds, axis=1)\n",
    "        std_predictions = np.std(stacked_preds, axis=1)\n",
    "\n",
    "        return avg_predictions, std_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "source": [
    "\n",
    "### MIXTURE DENSITY NETWORK (MDN) IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "class MDN(keras.Model):\n",
    "    def __init__(self, n_components=5, input_dim=None):\n",
    "        super(MDN, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # Define the model architecture\n",
    "        self.dense1 = layers.Dense(128, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.2)\n",
    "        self.dense2 = layers.Dense(64, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.2)\n",
    "        self.dense3 = layers.Dense(32, activation='relu')\n",
    "\n",
    "        # Output layers for mixture model\n",
    "        self.pi = layers.Dense(n_components, activation='softmax')  # Mixture weights\n",
    "        self.mu = layers.Dense(n_components)  # Means\n",
    "        self.sigma = layers.Dense(n_components, activation='softplus')  # Standard deviations\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Ensure input is correct dtype\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        pi = self.pi(x)\n",
    "        mu = self.mu(x)\n",
    "        sigma = self.sigma(x) + 1e-5  # Add small constant for numerical stability\n",
    "\n",
    "        return pi, mu, sigma\n",
    "\n",
    "    def loss_function(self, y_true, pi, mu, sigma):\n",
    "        # Ensure consistent dtypes\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        pi = tf.cast(pi, tf.float32)\n",
    "        mu = tf.cast(mu, tf.float32)\n",
    "        sigma = tf.cast(sigma, tf.float32)\n",
    "\n",
    "        # Build mixture of Gaussians using TFP\n",
    "        mix = tfd.Categorical(probs=pi)\n",
    "        comp = tfd.Normal(loc=mu, scale=sigma)\n",
    "        mixture = tfd.MixtureSameFamily(mixture_distribution=mix, components_distribution=comp)\n",
    "\n",
    "        # Calculate negative log likelihood\n",
    "        log_likelihood = mixture.log_prob(y_true[:, tf.newaxis])\n",
    "        return -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "    def sample(self, X, num_samples=1):\n",
    "        # Ensure input is correct dtype\n",
    "        X = tf.cast(X, tf.float32)\n",
    "\n",
    "        # Get distribution parameters\n",
    "        pi, mu, sigma = self(X)\n",
    "\n",
    "        # Create mixture model\n",
    "        mix = tfd.Categorical(probs=pi)\n",
    "        comp = tfd.Normal(loc=mu, scale=sigma)\n",
    "        mixture = tfd.MixtureSameFamily(mixture_distribution=mix, components_distribution=comp)\n",
    "\n",
    "        # Sample from the mixture\n",
    "        samples = mixture.sample(num_samples)\n",
    "\n",
    "        # Take mean across samples for point predictions\n",
    "        mean_samples = tf.reduce_mean(samples, axis=0)\n",
    "        return mean_samples.numpy()\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# MDN TRAINING IMPLEMENTATION\n",
    "# -------------------------------------------------------------------------\n",
    "def create_and_train_mdn(X_train_scaled, y_train_scaled, X_test_scaled, epochs=20):\n",
    "    try:\n",
    "        input_dim = X_train_scaled.shape[1]\n",
    "        mdn_model = MDN(n_components=5, input_dim=input_dim)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        # Training step\n",
    "        @tf.function\n",
    "        def train_step(X, y):\n",
    "            with tf.GradientTape() as tape:\n",
    "                pi, mu, sigma = mdn_model(X)\n",
    "                loss = mdn_model.loss_function(y, pi, mu, sigma)\n",
    "\n",
    "            gradients = tape.gradient(loss, mdn_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, mdn_model.trainable_variables))\n",
    "            return loss\n",
    "\n",
    "        # Training loop\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            epoch_loss = tf.keras.metrics.Mean()\n",
    "            for X_batch, y_batch in train_dataset:\n",
    "                loss = train_step(X_batch, y_batch)\n",
    "                epoch_loss.update_state(loss)\n",
    "\n",
    "            # Validation\n",
    "            val_loss = tf.keras.metrics.Mean()\n",
    "            for X_val, y_val in test_dataset:\n",
    "                pi, mu, sigma = mdn_model(X_val)\n",
    "                val_batch_loss = mdn_model.loss_function(y_val, pi, mu, sigma)\n",
    "                val_loss.update_state(val_batch_loss)\n",
    "\n",
    "            losses.append(epoch_loss.result().numpy())\n",
    "            val_losses.append(val_loss.result().numpy())\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss.result():.4f}, Val Loss: {val_loss.result():.4f}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if epoch > 5 and val_losses[-1] > val_losses[-2] > val_losses[-3]:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "        # Generate predictions\n",
    "        y_pred_mdn = mdn_model.sample(X_test_scaled)\n",
    "        y_pred_mdn_orig = y_scaler.inverse_transform(y_pred_mdn.reshape(-1, 1)).flatten()\n",
    "\n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('MDN Training History')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return mdn_model, y_pred_mdn_orig\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in MDN training: {e}\")\n",
    "        # Return fallback predictions\n",
    "        return None, np.full(y_test.shape, y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "source": [
    "\n",
    "#### WGAN-GP TRAINING IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "def create_and_train_wgan(X_train_scaled, y_train_scaled, X_test_scaled, epochs=100):\n",
    "    try:\n",
    "        # Initialize WGAN-GP\n",
    "        input_dim = X_train_scaled.shape[1]\n",
    "        wgan_model = WGAN_GP(input_dim=input_dim, latent_dim=100)\n",
    "\n",
    "        # Train model\n",
    "        print(\"Training CWGAN model...\")\n",
    "        wgan_model.train(X_train_scaled, y_train_scaled, epochs=epochs, batch_size=64, n_critic=5)\n",
    "\n",
    "        # Generate predictions with uncertainty\n",
    "        y_pred_wgan, y_std_wgan = wgan_model.predict(X_test_scaled, num_samples=1000)\n",
    "\n",
    "        # Convert back to original scale\n",
    "        y_pred_wgan_orig = y_scaler.inverse_transform(y_pred_wgan.reshape(-1, 1)).flatten()\n",
    "        y_std_wgan_orig = y_std_wgan * y_scaler.scale_\n",
    "\n",
    "        # Plot predictions with uncertainty\n",
    "        sample_size = min(200, len(y_test))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(sample_size), y_test[:sample_size], 'k-', label='Actual')\n",
    "        plt.plot(range(sample_size), y_pred_wgan_orig[:sample_size], 'r-', label='WGAN Prediction')\n",
    "        plt.fill_between(\n",
    "            range(sample_size),\n",
    "            y_pred_wgan_orig[:sample_size] - 1.96 * y_std_wgan_orig[:sample_size],\n",
    "            y_pred_wgan_orig[:sample_size] + 1.96 * y_std_wgan_orig[:sample_size],\n",
    "            alpha=0.3, color='red',\n",
    "            label='95% Confidence Interval'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title('CWGAN: Predictions with Uncertainty')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Energy (Wh)')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return wgan_model, y_pred_wgan_orig, y_std_wgan_orig\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in WGAN training: {e}\")\n",
    "        # Return fallback predictions\n",
    "        return None, np.full(y_test.shape, y_train.mean()), np.zeros(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "source": [
    "### GAUSSIAN PROCESS REGRESSOR IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "def create_and_train_gp(X_train, y_train, X_test):\n",
    "    \"\"\"Create and train a Gaussian Process model\"\"\"\n",
    "    try:\n",
    "        # Use a subset of data for GP to avoid computational issues\n",
    "        max_samples = 1000  # GP doesn't scale well to large datasets\n",
    "        if X_train.shape[0] > max_samples:\n",
    "            print(f\"Using {max_samples} samples for GP training (GP doesn't scale well)\")\n",
    "            indices = np.random.choice(X_train.shape[0], max_samples, replace=False)\n",
    "            X_train_subset = X_train.iloc[indices]\n",
    "            y_train_subset = y_train.iloc[indices]\n",
    "        else:\n",
    "            X_train_subset = X_train\n",
    "            y_train_subset = y_train\n",
    "\n",
    "        # Define kernel\n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "\n",
    "        # Initialize GP regressor\n",
    "        gp = GaussianProcessRegressor(\n",
    "            kernel=kernel,\n",
    "            alpha=0.1,  # Noise variance\n",
    "            normalize_y=True,  # Normalize target values\n",
    "            n_restarts_optimizer=5  # Number of optimizer restarts\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        print(\"Training Gaussian Process model...\")\n",
    "        gp.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "        # Generate predictions with uncertainty\n",
    "        y_pred_gp, y_std_gp = gp.predict(X_test, return_std=True)\n",
    "\n",
    "        # Plot predictions with uncertainty\n",
    "        sample_size = min(200, len(y_test))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(sample_size), y_test[:sample_size], 'k-', label='Actual')\n",
    "        plt.plot(range(sample_size), y_pred_gp[:sample_size], 'm-', label='GP Prediction')\n",
    "        plt.fill_between(\n",
    "            range(sample_size),\n",
    "            y_pred_gp[:sample_size] - 1.96 * y_std_gp[:sample_size],\n",
    "            y_pred_gp[:sample_size] + 1.96 * y_std_gp[:sample_size],\n",
    "            alpha=0.3, color='magenta',\n",
    "            label='95% Confidence Interval'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title('Gaussian Process: Predictions with Uncertainty')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Energy (Wh)')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return gp, y_pred_gp, y_std_gp\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in GP training: {e}\")\n",
    "        # Return fallback predictions\n",
    "        return None, np.full(y_test.shape, y_train.mean()), np.zeros(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "source": [
    "\n",
    "### QUANTILE REGRESSION IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "def create_and_train_qr(X_train, y_train, X_test):\n",
    "    \"\"\"Create and train Quantile Regression models\"\"\"\n",
    "    try:\n",
    "        quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "        qr_models = {}\n",
    "        qr_predictions = {}\n",
    "\n",
    "        for q in quantiles:\n",
    "            print(f\"Training Quantile Regression for q={q}\")\n",
    "            qr_models[q] = QuantileRegressor(\n",
    "                quantile=q,\n",
    "                alpha=0.1,  # L1 regularization\n",
    "                solver='highs'  # More stable solver\n",
    "            )\n",
    "            qr_models[q].fit(X_train, y_train)\n",
    "            qr_predictions[q] = qr_models[q].predict(X_test)\n",
    "\n",
    "        # Plot prediction intervals\n",
    "        sample_size = min(200, len(y_test))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(sample_size), y_test[:sample_size], 'k-', label='Actual')\n",
    "        plt.plot(range(sample_size), qr_predictions[0.5][:sample_size], 'b-', label='Median (Q50)')\n",
    "        plt.fill_between(\n",
    "            range(sample_size),\n",
    "            qr_predictions[0.1][:sample_size],\n",
    "            qr_predictions[0.9][:sample_size],\n",
    "            alpha=0.3, color='blue',\n",
    "            label='80% Prediction Interval (Q10-Q90)'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title('Quantile Regression: Prediction Intervals')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Energy (Wh)')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Calculate uncertainty as half the interval width\n",
    "        qr_uncertainty = (qr_predictions[0.9] - qr_predictions[0.1]) / 2\n",
    "\n",
    "        return qr_models, qr_predictions[0.5], qr_uncertainty\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in QR training: {e}\")\n",
    "        # Return fallback predictions\n",
    "        return None, np.full(y_test.shape, y_train.mean()), np.zeros(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "source": [
    "\n",
    "### BAYESIAN RIDGE REGRESSION IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "def create_and_train_br(X_train, y_train, X_test):\n",
    "    \"\"\"Create and train Bayesian Ridge Regression\"\"\"\n",
    "    try:\n",
    "        # Initialize model\n",
    "        br = BayesianRidge(\n",
    "            n_iter=300,\n",
    "            alpha_1=1e-6,\n",
    "            alpha_2=1e-6,\n",
    "            lambda_1=1e-6,\n",
    "            lambda_2=1e-6,\n",
    "            compute_score=True\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        print(\"Training Bayesian Ridge Regression model...\")\n",
    "        br.fit(X_train, y_train)\n",
    "\n",
    "        # Generate predictions with uncertainty\n",
    "        y_pred_br, y_std_br = br.predict(X_test, return_std=True)\n",
    "\n",
    "        # Plot predictions with uncertainty\n",
    "        sample_size = min(200, len(y_test))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(range(sample_size), y_test[:sample_size], 'k-', label='Actual')\n",
    "        plt.plot(range(sample_size), y_pred_br[:sample_size], 'g-', label='Bayesian Ridge Prediction')\n",
    "        plt.fill_between(\n",
    "            range(sample_size),\n",
    "            y_pred_br[:sample_size] - 1.96 * y_std_br[:sample_size],\n",
    "            y_pred_br[:sample_size] + 1.96 * y_std_br[:sample_size],\n",
    "            alpha=0.3, color='green',\n",
    "            label='95% Confidence Interval'\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title('Bayesian Ridge Regression: Confidence Intervals')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Energy (Wh)')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        return br, y_pred_br, y_std_br\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in BR training: {e}\")\n",
    "        # Return fallback predictions\n",
    "        return None, np.full(y_test.shape, y_train.mean()), np.zeros(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "def plot_residuals_vs_uncertainty(y_test, predictions, uncertainties):\n",
    "    \"\"\"Plot residuals vs uncertainty with robust error handling\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i, (model, pred) in enumerate(predictions.items()):\n",
    "        if model in uncertainties:\n",
    "            plt.subplot(2, 3, i+1)\n",
    "\n",
    "            residuals = y_test - pred\n",
    "            uncertainty = uncertainties[model]\n",
    "\n",
    "            # Check for invalid values\n",
    "            valid_indices = np.logical_and(\n",
    "                np.isfinite(uncertainty),\n",
    "                np.isfinite(residuals)\n",
    "            )\n",
    "\n",
    "            if not np.any(valid_indices):\n",
    "                plt.text(0.5, 0.5, \"Invalid data\",\n",
    "                         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "                plt.title(f\"{model}\\nNo valid data for analysis\")\n",
    "                continue\n",
    "\n",
    "            valid_uncertainty = uncertainty[valid_indices]\n",
    "            valid_residuals = residuals[valid_indices]\n",
    "\n",
    "            # Check if we have any variance in the data\n",
    "            if np.std(valid_uncertainty) < 1e-10:\n",
    "                plt.text(0.5, 0.5, \"No variance in uncertainty values\",\n",
    "                         ha='center', va='center', transform=plt.gca().transAxes)\n",
    "                plt.title(f\"{model}\\nConstant uncertainty\")\n",
    "                continue\n",
    "\n",
    "            # Plot the scatter with valid points only\n",
    "            plt.scatter(valid_uncertainty, np.abs(valid_residuals), alpha=0.5, s=10)\n",
    "\n",
    "            try:\n",
    "                # Add trend line - with error handling\n",
    "                z = np.polyfit(valid_uncertainty, np.abs(valid_residuals), 1)\n",
    "                p = np.poly1d(z)\n",
    "\n",
    "                # Sort for plotting\n",
    "                sorted_uncertainty = np.sort(valid_uncertainty)\n",
    "                plt.plot(sorted_uncertainty, p(sorted_uncertainty), \"r--\",\n",
    "                         label=f\"Trend: y={z[0]:.2f}x+{z[1]:.2f}\")\n",
    "\n",
    "                # Calculate correlation safely\n",
    "                if len(valid_uncertainty) > 1:\n",
    "                    corr = np.corrcoef(valid_uncertainty, np.abs(valid_residuals))[0, 1]\n",
    "                    correlation_text = f\"Correlation: {corr:.2f}\"\n",
    "                else:\n",
    "                    correlation_text = \"Insufficient data for correlation\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error fitting trend line for {model}: {e}\")\n",
    "                correlation_text = \"Trend fitting failed\"\n",
    "\n",
    "            plt.title(f\"{model}\\n{correlation_text}\")\n",
    "            plt.xlabel(\"Predicted Uncertainty\")\n",
    "            plt.ylabel(\"Absolute Error\")\n",
    "            if 'p' in locals():  # Only add legend if trend line was plotted\n",
    "                plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('uncertainty_vs_error.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61"
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Main Execution - \n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZszjXqFlNvZy",
    "outputId": "3a4c5ebf-631c-4f94-fb78-f1a0178eef61",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in BR training: __init__() got an unexpected keyword argument 'n_iter'\n",
      "Using 1000 samples for GP training (GP doesn't scale well)\n",
      "Training Gaussian Process model...\n",
      "Training Quantile Regression for q=0.1\n",
      "Training Quantile Regression for q=0.25\n",
      "Training Quantile Regression for q=0.5\n",
      "Training Quantile Regression for q=0.75\n",
      "Training Quantile Regression for q=0.9\n"
     ]
    }
   ],
   "source": [
    "def run_uncertainty_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Run all uncertainty models and analyze results\"\"\"\n",
    "    # Train and predict with Bayesian Ridge\n",
    "    br_model, y_pred_br, y_std_br = create_and_train_br(X_train, y_train, X_test)\n",
    "\n",
    "    # Train and predict with Gaussian Process\n",
    "    gp_model, y_pred_gp, y_std_gp = create_and_train_gp(X_train, y_train, X_test)\n",
    "\n",
    "    # Train and predict with Quantile Regression\n",
    "    qr_models, y_pred_qr, y_uncertainty_qr = create_and_train_qr(X_train, y_train, X_test)\n",
    "\n",
    "    # Train and predict with MDN\n",
    "    mdn_model, y_pred_mdn = create_and_train_mdn(X_train_scaled, y_train_scaled, X_test_scaled)\n",
    "\n",
    "    # Train and predict with WGAN-GP\n",
    "    wgan_model, y_pred_wgan, y_std_wgan = create_and_train_wgan(X_train_scaled, y_train_scaled, X_test_scaled)\n",
    "\n",
    "    # Collect all predictions and uncertainties\n",
    "    predictions = {\n",
    "        'BayesianRidge': y_pred_br,\n",
    "        'GaussianProcess': y_pred_gp,\n",
    "        'QuantileRegression': y_pred_qr,\n",
    "        'MDN': y_pred_mdn,\n",
    "        'WGAN': y_pred_wgan\n",
    "    }\n",
    "\n",
    "    uncertainties = {\n",
    "        'BayesianRidge': y_std_br,\n",
    "        'GaussianProcess': y_std_gp,\n",
    "        'QuantileRegression': y_uncertainty_qr,\n",
    "        'WGAN': y_std_wgan\n",
    "    }\n",
    "\n",
    "    # Evaluate individual models\n",
    "    results = {}\n",
    "    print(\"\\n======== MODEL EVALUATIONS ========\")\n",
    "    for model_name, y_pred in predictions.items():\n",
    "        metrics = evaluate_model(y_test, y_pred, model_name)\n",
    "        results[model_name] = metrics\n",
    "\n",
    "    # Summarize and output final recommendation\n",
    "    print(\"\\n======== FINAL MODEL RECOMMENDATION ========\")\n",
    "\n",
    "    # Print final scores\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    print(f\"{'Model':<20} {'RMSE':<10} {'MAE':<10} {'R²':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for model, metrics in results.items():\n",
    "        print(f\"{model:<20} {metrics['rmse']:.4f}{'':<5} {metrics['mae']:.4f}{'':<5} {metrics['r2']:.4f}\")\n",
    "\n",
    "    # Get best overall model based on RMSE\n",
    "    best_model = min(results.items(), key=lambda x: x[1]['rmse'])[0]\n",
    "\n",
    "    print(f\"\\nRECOMMENDED MODEL: {best_model}\")\n",
    "    print(f\"This model provides the best RMSE performance of {results[best_model]['rmse']:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'uncertainties': uncertainties,\n",
    "        'metrics': results,\n",
    "        'best_model': best_model\n",
    "    }\n",
    "\n",
    "# Call the main function if the script is run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming X_train, y_train, X_test, y_test are already defined\n",
    "    results = run_uncertainty_models(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Save results\n",
    "    import pickle\n",
    "    with open('uncertainty_modeling_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    print(\"\\nModel training and evaluation complete. Results saved to 'uncertainty_modeling_results.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models with predictions available: ['BayesianRidge', 'GaussianProcess', 'QuantileRegression', 'MDN', 'WGAN']\n",
      "Models with uncertainties available: ['BayesianRidge', 'GaussianProcess', 'QuantileRegression', 'WGAN']\n",
      "\n",
      "Evaluating all models with probabilistic metrics...\n",
      "\n",
      "Evaluating BayesianRidge...\n",
      "  Predictions dtype: float32, shape: (39351,), range: [0.1142, 0.1142]\n",
      "  Uncertainties dtype: float32, shape: (39351,), range: [0.0000, 0.0000]\n",
      "  Warning: Found 0 invalid predictions, 0 invalid uncertainties, 39351 zero uncertainties\n",
      "BayesianRidge Probabilistic Metrics:\n",
      "  CRPS: 0.0000\n",
      "  Pinball Loss: 0.0758\n",
      "  Interval Coverage (50%): 0.0000\n",
      "  Interval Coverage (90%): 0.0000\n",
      "  Interval Coverage (95%): 0.0000\n",
      "\n",
      "Evaluating GaussianProcess...\n",
      "  Predictions dtype: float32, shape: (39351,), range: [-0.1350, 0.9768]\n",
      "  Uncertainties dtype: float32, shape: (39351,), range: [0.0149, 0.1970]\n",
      "GaussianProcess Probabilistic Metrics:\n",
      "  CRPS: 0.0474\n",
      "  Pinball Loss: 0.0252\n",
      "  Interval Coverage (50%): 0.7459\n",
      "  Interval Coverage (90%): 0.8545\n",
      "  Interval Coverage (95%): 0.8758\n",
      "\n",
      "Evaluating QuantileRegression...\n",
      "  Predictions dtype: float32, shape: (39351,), range: [0.0000, 0.2748]\n",
      "  Uncertainties dtype: float32, shape: (39351,), range: [0.0000, 0.7575]\n",
      "  Warning: Found 0 invalid predictions, 0 invalid uncertainties, 4998 zero uncertainties\n",
      "QuantileRegression Probabilistic Metrics:\n",
      "  CRPS: nan\n",
      "  Pinball Loss: nan\n",
      "  Interval Coverage (50%): 0.8456\n",
      "  Interval Coverage (90%): 0.9319\n",
      "  Interval Coverage (95%): 0.9548\n",
      "\n",
      "Evaluating WGAN...\n",
      "  Predictions dtype: float32, shape: (39351,), range: [-0.6692, 1.3113]\n",
      "  Uncertainties dtype: float32, shape: (39351,), range: [0.0017, 0.0106]\n",
      "WGAN Probabilistic Metrics:\n",
      "  CRPS: 0.0145\n",
      "  Pinball Loss: 0.0199\n",
      "  Interval Coverage (50%): 0.0376\n",
      "  Interval Coverage (90%): 0.0920\n",
      "  Interval Coverage (95%): 0.1093\n",
      "\n",
      "===== PROBABILISTIC METRICS COMPARISON =====\n",
      "                         BayesianRidge  GaussianProcess  QuantileRegression  \\\n",
      "CRPS                          0.000000         0.047415                 NaN   \n",
      "Pinball Loss                  0.075776         0.025228                 NaN   \n",
      "Interval Coverage (50%)       0.000000         0.745851            0.845569   \n",
      "Interval Coverage (90%)       0.000000         0.854464            0.931870   \n",
      "Interval Coverage (95%)       0.000000         0.875759            0.954766   \n",
      "\n",
      "                             WGAN  \n",
      "CRPS                     0.014522  \n",
      "Pinball Loss             0.019880  \n",
      "Interval Coverage (50%)  0.037636  \n",
      "Interval Coverage (90%)  0.092018  \n",
      "Interval Coverage (95%)  0.109273  \n",
      "\n",
      "===== FINAL MODEL RECOMMENDATIONS =====\n",
      "Based on traditional metrics (RMSE): WGAN\n",
      "Based on probabilistic accuracy (CRPS): BayesianRidge\n",
      "Based on interval quality (Pinball Loss): WGAN\n",
      "Best calibrated intervals: GaussianProcess\n",
      "\n",
      "Comprehensive evaluation complete. Results saved to 'comprehensive_evaluation_results.pkl'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from probabilistic_metrics import (\n",
    "    continuous_ranked_probability_score,\n",
    "    pinball_loss,\n",
    "    wasserstein_distance,\n",
    "    interval_coverage,\n",
    "    energy_score,\n",
    "    generate_quantile_forecasts_from_gaussian,\n",
    "    plot_reliability_diagram\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fix the dtype issue by creating a wrapper function for CRPS\n",
    "def safe_crps(y_true, y_pred_mean, y_pred_std):\n",
    "    \"\"\"Safely calculate CRPS by ensuring consistent data types\"\"\"\n",
    "    # Convert all to the same data type (float32)\n",
    "    y_true = y_true.astype(np.float32)\n",
    "    y_pred_mean = y_pred_mean.astype(np.float32)\n",
    "    y_pred_std = y_pred_std.astype(np.float32)\n",
    "    \n",
    "    try:\n",
    "        # Try with TensorFlow Probability\n",
    "        import tensorflow_probability as tfp\n",
    "        \n",
    "        # Create a normal distribution for each prediction\n",
    "        distributions = [tfp.distributions.Normal(loc=mu, scale=sigma) \n",
    "                        for mu, sigma in zip(y_pred_mean, y_pred_std)]\n",
    "        \n",
    "        crps_values = []\n",
    "        for dist, actual in zip(distributions, y_true):\n",
    "            # Generate CDF evaluation points centered on actual value\n",
    "            eval_points = np.linspace(actual - 5 * dist.stddev(), actual + 5 * dist.stddev(), 100)\n",
    "            \n",
    "            # Calculate CDF values at evaluation points\n",
    "            cdf_values = dist.cdf(eval_points).numpy()\n",
    "            \n",
    "            # Step function for actual value (1 if x >= actual, 0 otherwise)\n",
    "            step_values = np.array([1.0 if x >= actual else 0.0 for x in eval_points])\n",
    "            \n",
    "            # Calculate CRPS as integral of squared difference\n",
    "            squared_diff = (cdf_values - step_values) ** 2\n",
    "            crps = np.trapz(squared_diff, eval_points)\n",
    "            crps_values.append(crps)\n",
    "        \n",
    "        return np.mean(crps_values)\n",
    "    \n",
    "    except (TypeError, ValueError) as e:\n",
    "        print(f\"Error in CRPS calculation: {e}\")\n",
    "        print(\"Falling back to simplified CRPS calculation...\")\n",
    "        \n",
    "        # Simplified CRPS calculation without TensorFlow Probability\n",
    "        from scipy.stats import norm\n",
    "        \n",
    "        crps_values = []\n",
    "        for mu, sigma, actual in zip(y_pred_mean, y_pred_std, y_true):\n",
    "            # Skip invalid values\n",
    "            if not np.isfinite(mu) or not np.isfinite(sigma) or not np.isfinite(actual) or sigma <= 0:\n",
    "                continue\n",
    "                \n",
    "            # Generate evaluation points\n",
    "            eval_points = np.linspace(actual - 5 * sigma, actual + 5 * sigma, 100)\n",
    "            \n",
    "            # Calculate CDF values using scipy\n",
    "            cdf_values = norm.cdf(eval_points, loc=mu, scale=sigma)\n",
    "            \n",
    "            # Step function\n",
    "            step_values = np.array([1.0 if x >= actual else 0.0 for x in eval_points])\n",
    "            \n",
    "            # CRPS calculation\n",
    "            squared_diff = (cdf_values - step_values) ** 2\n",
    "            crps = np.trapz(squared_diff, eval_points)\n",
    "            crps_values.append(crps)\n",
    "        \n",
    "        if len(crps_values) > 0:\n",
    "            return np.mean(crps_values)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "# Create a custom evaluation function that handles type inconsistencies\n",
    "def evaluate_models_with_safe_metrics(predictions, uncertainties, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate models with proper type handling\n",
    "    \"\"\"\n",
    "    # Convert y_test to numpy array if it's a pandas Series\n",
    "    y_test_np = y_test.values if isinstance(y_test, pd.Series) else y_test\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, y_pred in predictions.items():\n",
    "        if model_name in uncertainties:\n",
    "            print(f\"\\nEvaluating {model_name}...\")\n",
    "            \n",
    "            # Get the predictions and uncertainties\n",
    "            y_pred = np.array(y_pred).flatten()\n",
    "            y_std = np.array(uncertainties[model_name]).flatten()\n",
    "            \n",
    "            # Print data types and check for invalid values\n",
    "            print(f\"  Predictions dtype: {y_pred.dtype}, shape: {y_pred.shape}, range: [{np.min(y_pred):.4f}, {np.max(y_pred):.4f}]\")\n",
    "            print(f\"  Uncertainties dtype: {y_std.dtype}, shape: {y_std.shape}, range: [{np.min(y_std):.4f}, {np.max(y_std):.4f}]\")\n",
    "            \n",
    "            invalid_pred = np.sum(~np.isfinite(y_pred))\n",
    "            invalid_std = np.sum(~np.isfinite(y_std))\n",
    "            zero_std = np.sum(y_std == 0)\n",
    "            \n",
    "            if invalid_pred > 0 or invalid_std > 0 or zero_std > 0:\n",
    "                print(f\"  Warning: Found {invalid_pred} invalid predictions, {invalid_std} invalid uncertainties, {zero_std} zero uncertainties\")\n",
    "            \n",
    "            # Calculate safe CRPS\n",
    "            crps = safe_crps(y_test_np, y_pred, y_std)\n",
    "            \n",
    "            # Calculate Pinball Loss\n",
    "            quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "            quantile_forecasts = {}\n",
    "            for q in quantiles:\n",
    "                # Handle potential NaN or inf in predictions or uncertainties\n",
    "                valid_indices = np.logical_and(\n",
    "                    np.logical_and(np.isfinite(y_pred), np.isfinite(y_std)), \n",
    "                    y_std > 0\n",
    "                )\n",
    "                \n",
    "                if np.any(valid_indices):\n",
    "                    # Only compute for valid values\n",
    "                    from scipy.stats import norm\n",
    "                    q_values = np.full_like(y_pred, np.nan)\n",
    "                    q_values[valid_indices] = y_pred[valid_indices] + norm.ppf(q) * y_std[valid_indices]\n",
    "                    quantile_forecasts[q] = q_values\n",
    "                else:\n",
    "                    # If no valid values, use the predictions as fallback\n",
    "                    quantile_forecasts[q] = y_pred\n",
    "            \n",
    "            try:\n",
    "                pinball = pinball_loss(y_test_np, quantile_forecasts, quantiles)\n",
    "            except Exception as e:\n",
    "                print(f\"  Error in pinball loss calculation: {e}\")\n",
    "                pinball = np.nan\n",
    "            \n",
    "            # Calculate Interval Coverage\n",
    "            coverage_50 = interval_coverage(y_test_np, y_pred, y_std, 0.5)\n",
    "            coverage_90 = interval_coverage(y_test_np, y_pred, y_std, 0.9)\n",
    "            coverage_95 = interval_coverage(y_test_np, y_pred, y_std, 0.95)\n",
    "            \n",
    "            # Compile metrics\n",
    "            results[model_name] = {\n",
    "                'CRPS': crps,\n",
    "                'Pinball Loss': pinball,\n",
    "                'Interval Coverage (50%)': coverage_50,\n",
    "                'Interval Coverage (90%)': coverage_90,\n",
    "                'Interval Coverage (95%)': coverage_95\n",
    "            }\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"{model_name} Probabilistic Metrics:\")\n",
    "            for metric_name, value in results[model_name].items():\n",
    "                print(f\"  {metric_name}: {value:.4f}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Print comparison\n",
    "    print(\"\\n===== PROBABILISTIC METRICS COMPARISON =====\")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Save to CSV\n",
    "    results_df.to_csv('probabilistic_metrics_comparison.csv')\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    if len(results) > 0:\n",
    "        plot_model_comparison(results_df)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def plot_model_comparison(results_df):\n",
    "    \"\"\"Create visualization comparing models on probabilistic metrics\"\"\"\n",
    "    # Plot interval coverage comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    models = results_df.columns\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.25\n",
    "    \n",
    "    # Plot coverage metrics\n",
    "    plt.bar(x - width, results_df.loc['Interval Coverage (50%)'], width=width, label='50% Coverage')\n",
    "    plt.bar(x, results_df.loc['Interval Coverage (90%)'], width=width, label='90% Coverage')\n",
    "    plt.bar(x + width, results_df.loc['Interval Coverage (95%)'], width=width, label='95% Coverage')\n",
    "    \n",
    "    # Add reference lines\n",
    "    plt.axhline(0.5, color='r', linestyle='--', alpha=0.3)\n",
    "    plt.axhline(0.9, color='g', linestyle='--', alpha=0.3)\n",
    "    plt.axhline(0.95, color='b', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Actual Coverage')\n",
    "    plt.title('Prediction Interval Coverage by Model')\n",
    "    plt.xticks(x, models)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_coverage_comparison.png')\n",
    "    \n",
    "    # Plot error metrics\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Only plot metrics that have valid values\n",
    "    valid_metrics = ['Pinball Loss']\n",
    "    if not np.isnan(results_df.loc['CRPS']).all():\n",
    "        valid_metrics.append('CRPS')\n",
    "    \n",
    "    for i, metric in enumerate(valid_metrics):\n",
    "        plt.subplot(1, len(valid_metrics), i+1)\n",
    "        plt.bar(models, results_df.loc[metric], color='skyblue')\n",
    "        plt.title(f'{metric} (lower is better)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_error_metrics.png')\n",
    "\n",
    "# Get your data directly from the results dictionary\n",
    "predictions = results['predictions']\n",
    "uncertainties = results['uncertainties']\n",
    "\n",
    "# Make sure all values are numeric arrays\n",
    "for model in predictions:\n",
    "    predictions[model] = np.array(predictions[model]).astype(np.float32)\n",
    "    \n",
    "for model in uncertainties:\n",
    "    uncertainties[model] = np.array(uncertainties[model]).astype(np.float32)\n",
    "\n",
    "# Print what models are available for evaluation\n",
    "print(\"Models with predictions available:\", list(predictions.keys()))\n",
    "print(\"Models with uncertainties available:\", list(uncertainties.keys()))\n",
    "\n",
    "# Run the evaluation with the safer function\n",
    "print(\"\\nEvaluating all models with probabilistic metrics...\")\n",
    "prob_metrics_df = evaluate_models_with_safe_metrics(predictions, uncertainties, y_test)\n",
    "\n",
    "# Print final recommendations\n",
    "try:\n",
    "    print(\"\\n===== FINAL MODEL RECOMMENDATIONS =====\")\n",
    "    print(f\"Based on traditional metrics (RMSE): {results['best_model']}\")\n",
    "\n",
    "    # Find best models based on probabilistic metrics (handling NaN values)\n",
    "    crps_values = prob_metrics_df.loc['CRPS']\n",
    "    pinball_values = prob_metrics_df.loc['Pinball Loss']\n",
    "    \n",
    "    if not np.isnan(crps_values).all():\n",
    "        best_crps = crps_values.dropna().idxmin() if not crps_values.dropna().empty else \"N/A\"\n",
    "        print(f\"Based on probabilistic accuracy (CRPS): {best_crps}\")\n",
    "    else:\n",
    "        print(\"CRPS values are not available for comparison\")\n",
    "        \n",
    "    if not np.isnan(pinball_values).all():\n",
    "        best_pinball = pinball_values.dropna().idxmin() if not pinball_values.dropna().empty else \"N/A\"\n",
    "        print(f\"Based on interval quality (Pinball Loss): {best_pinball}\")\n",
    "    else:\n",
    "        print(\"Pinball Loss values are not available for comparison\")\n",
    "\n",
    "    # Check interval coverage - find the model with coverage closest to the nominal levels\n",
    "    coverage_errors = {}\n",
    "    for model in prob_metrics_df.columns:\n",
    "        if model in uncertainties:\n",
    "            err_50 = abs(prob_metrics_df.loc['Interval Coverage (50%)'][model] - 0.5)\n",
    "            err_90 = abs(prob_metrics_df.loc['Interval Coverage (90%)'][model] - 0.9)\n",
    "            err_95 = abs(prob_metrics_df.loc['Interval Coverage (95%)'][model] - 0.95)\n",
    "            coverage_errors[model] = (err_50 + err_90 + err_95) / 3\n",
    "\n",
    "    if coverage_errors:\n",
    "        best_calibrated = min(coverage_errors.items(), key=lambda x: x[1])[0]\n",
    "        print(f\"Best calibrated intervals: {best_calibrated}\")\n",
    "        \n",
    "    # Save the comprehensive evaluation results\n",
    "    import pickle\n",
    "    with open('comprehensive_evaluation_results.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'traditional_metrics': results['metrics'],\n",
    "            'probabilistic_metrics': prob_metrics_df\n",
    "        }, f)\n",
    "\n",
    "    print(\"\\nComprehensive evaluation complete. Results saved to 'comprehensive_evaluation_results.pkl'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error when generating final recommendations: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
